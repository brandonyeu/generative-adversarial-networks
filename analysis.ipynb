{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWm+dHr56aLlqxqgRsRFep"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks\n",
        "### Brandon Yeu\n",
        "\n",
        "1. GAN training is modeled as a two-player minimax game between a generator, which tries to produce fake data that appears real, and a discriminator, which tries to identify real or fake data. The generator's goal is to minimize the discriminator's success, but the discriminator's goal is to maximize its success.\n",
        "\n",
        "2. GANs are powerful, but it can often be difficult to train them. One common challenge is mode collapse, in which the generator produces a limited variety of outputs, as opposed to a diverse set of realistic data. This can cause the model to map different latent inputs to the same/similar samples. Mode collapse can occur if the reward function is not diverse or if the generator finds a quick way to exploit the discriminator. Techniques such as batch normalization, minibatch discrimination, and Wassertein GAN can help mitigate mode collapse.\n",
        "\n",
        "3. In an adversarial network, the discriminator is an adaptive loss function for the generator. It helps to dynamically train the model, and it improves with the generator continuously redefining how they function during training.\n",
        "\n",
        "4. Inception score (IS) evaluates GAN performances by rewarding high confidence predictions and high diversity, but it ignores real data distribution, can be bypassed by sharp, but unrealistic images, and is sensitive to the pretrained classifier. Fréchet inception distance (FID) evaluates GAN performances by comparing statistics of real and generated images in feature space. FID measures image quality compared to real images and diversity, so it better correlates with human comparison and penalizes mode collapse."
      ],
      "metadata": {
        "id": "_ocw5rkEI8u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load and preprocess data\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(-1, 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize to [-1, 1]\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Generator model\n",
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Reshape((7, 7, 256)),\n",
        "      layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "# Discriminator model\n",
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "# Loss functions\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV6WpAo5X5-m",
        "outputId": "e09b1527-1cd4-41fc-faf3-f449ad607501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Optimizers\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Training function\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, 100])\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "# Run the training\n",
        "train(train_dataset, epochs=50)"
      ],
      "metadata": {
        "id": "wmTvkBk8Y9nW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}