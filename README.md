# generative-adversarial-networks

## Overview

This project implements and experiments with a **Deep Convolutional Generative Adversarial Network (DCGAN)** using TensorFlow and Keras.  
The original starter GAN code (designed for MNIST) was extended and modified to:

- Use the **CIFAR-10 dataset**
- Support **32×32 RGB images**
- Add **additional convolutional layers** to the generator
- Save generated images **every 10 epochs** to visualize training progress

The goal of this is to understand adversarial training, GAN stability, and how architectural changes affect image quality.

---

## Dataset

- **Dataset:** CIFAR-10  
- **Image size:** 32 × 32  
- **Channels:** 3 (RGB)  
- **Preprocessing:**
  - Images are normalized to the range **[-1, 1]**
  - Labels are not used (unsupervised learning)

---

## Model Architecture

### Generator

The generator takes a 100-dimensional random noise vector and progressively upsamples it into a 32×32×3 image using transposed convolutions.

Key features:
- Dense layer followed by reshape to 4×4×512
- **Multiple Conv2DTranspose layers** for deeper representation learning
- Batch Normalization and LeakyReLU activations
- Final `tanh` activation to match normalized image range

**Output:** 32×32 RGB image

---

### Discriminator

The discriminator is a convolutional neural network that classifies images as real or fake.

Key features:
- Multiple Conv2D layers
- LeakyReLU activations
- Dropout for regularization

---

## Loss Functions

- **Discriminator Loss:** Binary cross-entropy loss on real and fake images
- **Generator Loss:** Binary cross-entropy loss encouraging fake images to be classified as real

The discriminator and generator are trained alternately using adversarial loss.

---

## Training Details

- **Optimizer:** Adam (`lr = 1e-4`, `β₁ = 0.5`)
- **Batch size:** 256
- **Epochs:** 50
- **Noise dimension:** 100
- **Image saving interval:** Every 10 epochs

---

## Training Progress (Saved Samples)

The following images show samples generated by the model at different stages of training.

### Epoch 10
![Epoch 10](generated_images/image_at_epoch_0010.png)

### Epoch 20
![Epoch 20](generated_images/image_at_epoch_0020.png)

### Epoch 30
![Epoch 30](generated_images/image_at_epoch_0030.png)

### Epoch 40
![Epoch 40](generated_images/image_at_epoch_0040.png)

### Epoch 50
![Epoch 50](generated_images/image_at_epoch_0050.png)

---

## Observations

- Early epochs show noisy and unstructured images
- As training progresses, shapes and colors become more coherent
- Some artifacts remain, reflecting common GAN training challenges such as instability and partial mode collapse

---

## Conclusion

This project demonstrates how modifying GAN architectures and datasets affects training dynamics and output quality.  
By transitioning from MNIST to CIFAR-10 and deepening the generator, the model learns richer visual representations, though adversarial training remains challenging.
